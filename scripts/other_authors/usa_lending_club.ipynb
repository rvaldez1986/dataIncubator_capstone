{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LENDING CLUB\n",
    "\n",
    "https://www.kaggle.com/janiobachmann/lending-club-risk-analysis-and-metrics\n",
    "\n",
    "https://www.kaggle.com/wendykan/lending-club-loan-data?select=loan.csv\n",
    "\n",
    "https://www.lendingclub.com/business/landing/\n",
    "\n",
    "https://help.lendingclub.com/hc/en-us/articles/216127897-What-happens-when-a-loan-is-charged-off-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/USA/LC/loan.csv', low_memory=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets' transform the issue dates by year.\n",
    "df['issue_d'].head()\n",
    "dt_series = pd.to_datetime(df['issue_d'])\n",
    "df['year'] = dt_series.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"loan_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we do not use grace period\n",
    "bad_loan = [\"Charged Off\", \"Default\", \"Does not meet the credit policy. Status:Charged Off\", \n",
    "                \"Late (16-30 days)\", \"Late (31-120 days)\"]\n",
    "\n",
    "#we do not use curren loans\n",
    "good_loan = [\"Fully Paid\"]\n",
    "\n",
    "df['loan_condition'] = np.nan\n",
    "\n",
    "def loan_condition(status):\n",
    "    if status in bad_loan:\n",
    "        return 'Bad Loan'\n",
    "    elif status in good_loan:\n",
    "        return 'Good Loan'\n",
    "    else:\n",
    "        return 'Active'\n",
    "    \n",
    "    \n",
    "df['loan_condition'] = df['loan_status'].apply(loan_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"loan_condition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(16,6))\n",
    "\n",
    "colors = [\"#3791D7\", \"#7FFF00\", \"#D72626\"]\n",
    "labels =\"Good Loans\", \"Active Loans\", \"Bad Loans\" \n",
    "\n",
    "plt.suptitle('Information on Loan Conditions', fontsize=20)\n",
    "\n",
    "df[\"loan_condition\"].value_counts().plot.pie(explode=[0,0.05, 0.20], autopct='%1.2f%%', ax=ax[0], shadow=True, colors=colors, \n",
    "                                             labels=labels, fontsize=12, startangle=70)\n",
    "\n",
    "\n",
    "# ax[0].set_title('State of Loan', fontsize=16)\n",
    "ax[0].set_ylabel('% of Condition of Loans', fontsize=14)\n",
    "\n",
    "# sns.countplot('loan_condition', data=df, ax=ax[1], palette=colors)\n",
    "# ax[1].set_title('Condition of Loans', fontsize=20)\n",
    "# ax[1].set_xticklabels(['Good', 'Bad'], rotation='horizontal')\n",
    "palette = [\"#7FFF00\", \"#3791D7\", \"#D72626\"]\n",
    "\n",
    "sns.barplot(x=\"year\", y=\"loan_amnt\", hue=\"loan_condition\", data=df, palette=palette, estimator=lambda x: len(x) / len(df) * 100)\n",
    "ax[1].set(ylabel=\"(%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df.loan_condition != 'Active'].copy().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['addr_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = df2[['addr_state', \"loan_amnt\"]].groupby(['addr_state']).sum().sort_values(by=['loan_amnt'], ascending=False).head(10)\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "\n",
    "cmap = plt.cm.coolwarm\n",
    "cmap2 = plt.cm.coolwarm_r\n",
    "\n",
    "loans_by_regGrade = df2.groupby(['addr_state', 'grade']).size()[list(states.index)]\n",
    "loans_by_regGrade.unstack().plot(kind='bar', stacked=True, colormap=cmap, ax=ax[0], grid=False)\n",
    "\n",
    "loans_by_regCond = df2.groupby(['addr_state', 'loan_condition']).size()[list(states.index)]\n",
    "loans_by_regCond.unstack().plot(kind='bar', stacked=True, colormap=cmap, ax=ax[1], grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize=(16,8))\n",
    "\n",
    "cmap = plt.cm.coolwarm_r\n",
    "\n",
    "loans_by_regCond = df2[df2.grade.isin(['A','B'])].groupby(['addr_state', 'loan_condition']).size()[list(states.index)]\n",
    "axes = loans_by_regCond.unstack().plot(kind='bar', stacked=True, colormap=cmap, ax=ax, grid=False)\n",
    "state_pcts = loans_by_regCond.groupby(level=0).apply(lambda x: x / float(x.sum()))\n",
    "v = list(state_pcts.xs('Bad Loan', level=1, drop_level=False))\n",
    "\n",
    "def autolabel(axes, v):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"   \n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        height = axes.patches[i]._height+axes.patches[i+10]._height\n",
    "        \n",
    "        ax.text(i-0.2, 1000+height, '{}%'.format(round(v[i]*100,2)))\n",
    "\n",
    "autolabel(axes, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.addr_state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annual Income, Employment, loan amount, home, year of the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Process Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "\n",
    "class ColumnSelectTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, col_names):\n",
    "        self.col_names = col_names  # We will need these in transform()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything about the data,\n",
    "        # so it can just return self without any further processing\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Return an array with the same number of rows as X and one\n",
    "        # column for each in self.col_names\n",
    "        \n",
    "        X = X[self.col_names + ['loan_condition']].dropna().reset_index().copy()        \n",
    "        return X[self.col_names], X['loan_condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class ScalerEncoderTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.orColumns = []\n",
    "        self.scColumns = []\n",
    "        self.encColumns = []\n",
    "        self.scaler = None     \n",
    "        self.encoder = None\n",
    "        self.feature_Names = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything about the data,\n",
    "        # so it can just return self without any further processing\n",
    "        self.orColumns = X.columns\n",
    "        self.scColumns = [x for x,y in zip(X.columns,X.dtypes) if y !=  'object']\n",
    "        self.encColumns = [x for x in X.columns if x not in self.scColumns]\n",
    "        self.scaler = StandardScaler()\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "        self.scaler.fit(X[self.scColumns])\n",
    "        self.encoder.fit(X[self.encColumns])  \n",
    "        self.feature_Names = self.scColumns + list(self.encoder.get_feature_names(self.encColumns))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Return an array with the same number of rows as X and one\n",
    "        # column for each in self.col_names         \n",
    "        scaled = self.scaler.transform(X[self.scColumns])\n",
    "        encoded = self.encoder.transform(X[self.encColumns]).toarray()    \n",
    "        return np.concatenate((scaled,encoded),axis=1)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "\n",
    "We can create a database y_SB, X = [default_knn_SA, SAB, DAB] \n",
    "\n",
    "We must build a similarity index SAB between states A, B.\n",
    "\n",
    "We must build a direction value (AB vs. BA)\n",
    "\n",
    "### Create Compare database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use only a list of the first 30 states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_states = ['CA','TX','NY','FL','IL','NJ','PA','OH','GA',\n",
    "    'VA','NC','MI','AZ','MD','MA','CO','WA','MN','IN','MO','TN','NV','CT','WI','AL','OR','SC','LA','KY','OK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let create a compare list cmp_list = \\[index, curr_state, compare_state\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_state(state):\n",
    "    if state in possible_states:\n",
    "        poss_states2 = [x for x in possible_states if x != state]\n",
    "        c_state = np.random.choice(poss_states2, 1)[0]\n",
    "        return state,c_state   \n",
    "    else:\n",
    "        return None,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_list = [[x,y[0],y[1]] for x,y in zip(df2.index, df2.addr_state.apply(sample_state))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Necessary Models\n",
    "\n",
    "\n",
    "### Build a model for one person from Texas using California data\n",
    "\n",
    "Build state databases, fit neighbors in that database, keep the reference in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnvars = ['annual_inc','emp_length','loan_amnt','home_ownership','term', 'year']\n",
    "cst = ColumnSelectTransformer(knnvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 100 neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dKnn = {}\n",
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "for s in possible_states:\n",
    "    df_s = df2[df2.addr_state == s]\n",
    "    X,y = cst.transform(df_s)\n",
    "    cst2 = ScalerEncoderTransformer()    \n",
    "    X2 = cst2.fit_transform(X)\n",
    "    dKnn[s] = [NearestNeighbors(n_neighbors=n).fit(X2), y, cst2]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a texas person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txPerson = df2[df2.addr_state == 'TX'].iloc[[10]]\n",
    "txPerson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the features we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txPerson, _ = cst.transform(txPerson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We standarize the features using Scaler and Encoder fitted with California data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txPerson2 = dKnn['CA'][2].transform(txPerson)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we select 100 people who are similar, using California data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, indices = dKnn['CA'][0].kneighbors([txPerson2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the default vs non default in their outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simPplndex = indices[0]\n",
    "dKnn['CA'][1][simPplndex].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default probability is then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dKnn['CA'][1][simPplndex]=='Bad Loan')/len(dKnn['CA'][1][simPplndex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted probability of default is 24%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a check model  (predict Texas using 1 Texas)\n",
    "\n",
    "First we must **adjust our df for NAs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnvars = ['annual_inc','emp_length','loan_amnt','home_ownership','term', 'year']\n",
    "possible_states = ['CA','TX','NY','FL','IL','NJ','PA','OH','GA',\n",
    "    'VA','NC','MI','AZ','MD','MA','CO','WA','MN','IN','MO','TN','NV','CT','WI','AL','OR','SC','LA','KY','OK']\n",
    "\n",
    "for c in knnvars:\n",
    "    df2 = df2[df2[c].notna()]   #remove entries with na on my columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the parameter as selection only 1 neighbor and fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dKnn = {}\n",
    "n = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "cst = ColumnSelectTransformer(knnvars)\n",
    "for s in possible_states:\n",
    "    df_s = df2[df2.addr_state == s]\n",
    "    X,y = cst.transform(df_s)\n",
    "    cst2 = ScalerEncoderTransformer()    \n",
    "    X2 = cst2.fit_transform(X)\n",
    "    dKnn[s] = [NearestNeighbors(n_neighbors=n).fit(X2), y, cst2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the first 100 people from Texas (Note we extract our true **y** from them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txPersons = df2[df2.addr_state == 'TX'].head(100)\n",
    "txPersons,y = cst.transform(txPersons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict using our model for this 100 people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "for i in range(txPersons.shape[0]):\n",
    "    Person = txPersons.iloc[[i]]\n",
    "    Person2 = dKnn['TX'][2].transform(Person)[0]\n",
    "    distance, indices = dKnn['TX'][0].kneighbors([Person2])\n",
    "    simPplndex = indices[0]    \n",
    "    p = sum(dKnn['TX'][1][simPplndex]=='Bad Loan')/len(dKnn['TX'][1][simPplndex]) \n",
    "    probs.append(p)  \n",
    "    \n",
    "y_score = np.array(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform original y to the 0-1 space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y.map({'Good Loan':0, 'Bad Loan':1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we construct the ROC curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y, y_score, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain what we expected a perfect model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a knn predict model in sklearn\n",
    "\n",
    "Select a texas person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "\n",
    "class ColumnSelectTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, col_names):\n",
    "        self.col_names = col_names  # We will need these in transform()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything about the data,\n",
    "        # so it can just return self without any further processing\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Return an array with the same number of rows as X and one\n",
    "        # column for each in self.col_names\n",
    "        \n",
    "        X = X[self.col_names + ['loan_condition']].dropna().reset_index().copy()        \n",
    "        return X[self.col_names], X['loan_condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class ScalerEncoderTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.orColumns = []\n",
    "        self.scColumns = []\n",
    "        self.encColumns = []\n",
    "        self.scaler = None     \n",
    "        self.encoder = None\n",
    "        self.feature_Names = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything about the data,\n",
    "        # so it can just return self without any further processing\n",
    "        self.orColumns = X.columns\n",
    "        self.scColumns = [x for x,y in zip(X.columns,X.dtypes) if y !=  'object']\n",
    "        self.encColumns = [x for x in X.columns if x not in self.scColumns]\n",
    "        self.scaler = StandardScaler()\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "        self.scaler.fit(X[self.scColumns])\n",
    "        self.encoder.fit(X[self.encColumns])  \n",
    "        self.feature_Names = self.scColumns + list(self.encoder.get_feature_names(self.encColumns))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Return an array with the same number of rows as X and one\n",
    "        # column for each in self.col_names         \n",
    "        scaled = self.scaler.transform(X[self.scColumns])\n",
    "        encoded = self.encoder.transform(X[self.encColumns]).toarray()    \n",
    "        return np.concatenate((scaled,encoded),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class knnEstimator(base.BaseEstimator, base.RegressorMixin):\n",
    "    \n",
    "    def __init__(self, knnVars=[], possible_states=[]):\n",
    "        self.knnVars = knnVars\n",
    "        self.possible_states = possible_states\n",
    "        self.cst = ColumnSelectTransformer(self.knnVars)\n",
    "        self.dKnn_ = {}\n",
    "\n",
    "    \n",
    "    def fit(self, X, n):\n",
    "        # fit dictionary\n",
    "        for s in self.possible_states:\n",
    "            X2 = X[X.addr_state == s]\n",
    "            X3,y = self.cst.transform(X2)\n",
    "            cst2 = ScalerEncoderTransformer()    \n",
    "            X4 = cst2.fit_transform(X3)\n",
    "            self.dKnn_[s] = [NearestNeighbors(n_neighbors=n).fit(X4), y, cst2]   \n",
    "            \n",
    "    def pred_ind(self, Person, s):  #predict for Person using state s\n",
    "        Person, _ = self.cst.transform(Person)\n",
    "        Person2 = self.dKnn_[s][2].transform(Person)[0]\n",
    "        distance, indices = self.dKnn_[s][0].kneighbors([Person2])\n",
    "        simPplndex = indices[0]  #indices of similar people\n",
    "        p = sum(self.dKnn_[s][1][simPplndex]=='Bad Loan')/len(self.dKnn_[s][1][simPplndex])  #probability of bad loan\n",
    "        return p       \n",
    "        \n",
    "    \n",
    "    def predict(self, X, states):\n",
    "        probs = []\n",
    "        for i in range(X.shape[0]):\n",
    "            Person = X.iloc[[i]]\n",
    "            p = self.pred_ind(Person, states[i])\n",
    "            probs.append(p)              \n",
    "        return np.array(probs)\n",
    "    \n",
    "    def score(self, X, states, y):\n",
    "        y_scores = self.predict(X, states)\n",
    "        return roc_auc_score(y, y_scores)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnvars = ['annual_inc','emp_length','loan_amnt','home_ownership','term', 'year']\n",
    "possible_states = ['CA','TX','NY','FL','IL','NJ','PA','OH','GA',\n",
    "    'VA','NC','MI','AZ','MD','MA','CO','WA','MN','IN','MO','TN','NV','CT','WI','AL','OR','SC','LA','KY','OK']\n",
    "\n",
    "knnEst = knnEstimator(knnvars, possible_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnEst.fit(df2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txPersons = df2[df2.addr_state == 'TX'].head(100)\n",
    "states = ['TX']*len(txPersons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = knnEst.predict(txPersons, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(txPersons['loan_condition'].map({'Good Loan':0, 'Bad Loan':1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y, y_score, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnEst.fit(df2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txPersons = df2[df2.addr_state == 'TX'].head(3000)\n",
    "states = ['CA']*len(txPersons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = knnEst.predict(txPersons, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(txPersons['loan_condition'].map({'Good Loan':0, 'Bad Loan':1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y, y_score, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnEst.score(txPersons, states, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the database using the models fitted with knn for each state\n",
    "\n",
    "Fill using the pairs that we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n",
    "\n",
    "Create plot from similarities, ex california"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_state = pd.read_csv('../data/USA/State/state_data.csv', low_memory=False)\n",
    "\n",
    "df_state.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state2 = pd.DataFrame(scaler.fit_transform(df_state[['GDP_PC','gini','cost_living','hdi']]), \n",
    "                             columns=['GDP_PC','gini','cost_living','hdi'])\n",
    "df_state2 = pd.concat([df_state[['N','State_Name','Code']], df_state2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib  #save trained scaler\n",
    "joblib.dump(scaler, '..\\\\app\\\\demo1\\\\data\\\\state_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state2.to_pickle('..\\\\app\\\\demo1\\\\data\\\\df_state2.pkl')  #save it to model for using it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for predicting similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from sklearn.externals import joblib  #save trained scaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def GaussianKernel(v1, v2, sigma):\n",
    "    l2norm = distance.euclidean(v1, v2)\n",
    "    return np.exp(-l2norm**2/(2.*sigma**2))\n",
    "\n",
    "def state_simil(df, x):\n",
    "    df2 = df.copy()  #de reference\n",
    "    sim_index = []\n",
    "    for i in df2.index:\n",
    "        x2 = np.array(df2.loc[i][3:])\n",
    "        sim_index.append(GaussianKernel(x, x2, 1))\n",
    "    df2['sim_index'] = sim_index\n",
    "    return df2\n",
    "\n",
    "scaler = joblib.load( '..\\\\app\\\\demo1\\\\data\\\\state_scaler.pkl')\n",
    "df_state2 = pd.read_pickle('..\\\\app\\\\demo1\\\\data\\\\df_state2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare California and see how the states compare to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cal0 = np.array([74205,0.4899,148.53,5.40])  #Original entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cal = scaler.transform(x_cal0.reshape(1, -1))[0]\n",
    "x_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state3 = state_simil(df_state2, x_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "for col in df_state3.columns:\n",
    "    df_state3[col] = df_state3[col].astype(str)\n",
    "    \n",
    "scl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(0,191,255)'],[0.4, 'rgb(30,144,255)'],\\\n",
    "                [0.6, 'rgb(0,0,255)'],[0.8, 'rgb(0,0,205)'],[1.0, 'rgb(0,0,139)']]\n",
    "\n",
    "\n",
    "\n",
    "data = [ dict(\n",
    "        type='choropleth',\n",
    "        colorscale = scl,\n",
    "        autocolorscale = False,\n",
    "        locations = df_state3['Code'],\n",
    "        z = df_state3['sim_index'], \n",
    "        locationmode = 'USA-states',       \n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                #color = 'rgb(0,0,0)',\n",
    "                color = 'black',\n",
    "                width = 1.5\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            title = \"%\")\n",
    "        ) ]\n",
    "\n",
    "\n",
    "layout = dict(\n",
    "    title = 'State Similarity<br>(Hover for breakdown)',\n",
    "    geo = dict(\n",
    "        scope = 'usa',\n",
    "        projection=dict(type='albers usa'),\n",
    "        showlakes = True,\n",
    "        lakecolor = 'rgb(255, 255, 255)')\n",
    "        \n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig, filename='d3-cloropleth-map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do it for Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tx = np.array(df_state2.loc[43][3:])\n",
    "x_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state3 = state_simil(df_state2, x_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "for col in df_state3.columns:\n",
    "    df_state3[col] = df_state3[col].astype(str)\n",
    "    \n",
    "scl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(0,191,255)'],[0.4, 'rgb(30,144,255)'],\\\n",
    "                [0.6, 'rgb(0,0,255)'],[0.8, 'rgb(0,0,205)'],[1.0, 'rgb(0,0,139)']]\n",
    "\n",
    "\n",
    "\n",
    "data = [ dict(\n",
    "        type='choropleth',\n",
    "        colorscale = scl,\n",
    "        autocolorscale = False,\n",
    "        locations = df_state3['Code'],\n",
    "        z = df_state3['sim_index'], \n",
    "        locationmode = 'USA-states',       \n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                #color = 'rgb(0,0,0)',\n",
    "                color = 'black',\n",
    "                width = 1.5\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            title = \"%\")\n",
    "        ) ]\n",
    "\n",
    "\n",
    "layout = dict(\n",
    "    title = 'State Similarity<br>(Hover for breakdown)',\n",
    "    geo = dict(\n",
    "        scope = 'usa',\n",
    "        projection=dict(type='albers usa'),\n",
    "        showlakes = True,\n",
    "        lakecolor = 'rgb(255, 255, 255)')\n",
    "        \n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig, filename='d3-cloropleth-map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
